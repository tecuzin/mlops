---
alwaysApply: true
---

# Spécification des Workers

Les trois workers fonctionnent en mode **poll-based** : ils interrogent l'API à intervalle régulier pour détecter les runs à traiter.

## Architecture commune

Pattern partagé par les trois workers :

```python
def poll_loop():
    while True:
        runs = GET /runs?status=...
        for run in filtered_runs:
            try:
                process_run(run)
            except Exception:
                _notify(run_id, "failed", error=traceback)
        time.sleep(POLL_INTERVAL)
```

Fonctions utilitaires communes :
- `_notify(run_id, status, logs, metrics, error)` — met à jour le statut/logs/résultats via l'API
- `_log(run_id, message)` — log local + push vers l'API
- `_resolve_dataset_path(run, ds_type)` — récupère le chemin fichier via `GET /datasets`

Variables d'environnement :
- `API_URL` (default `http://api:8000`)
- `MLFLOW_TRACKING_URI` (default `http://mlflow:5000`)
- `POLL_INTERVAL` (default `10` secondes)
- `OUTPUT_DIR` (default `/app/outputs`)

## Worker Training (`workers/training/worker.py`)

### Déclenchement
- Poll les runs avec `status=pending` ET `task_type=finetune`

### Étapes de `process_run(run)`

1. **Status → "training"** + log des hyperparamètres
2. **MLflow** : `set_experiment()` + `start_run()`
3. **Téléchargement modèle** : `huggingface_hub.snapshot_download()` avec filtre sur les patterns `.json`, `.safetensors`, `.bin`, `.model`, `.txt`, `.py`
4. **Chargement tokenizer** : `AutoTokenizer.from_pretrained(cache_dir)`, pad_token = eos_token si absent
5. **Log architecture** : type, couches, dimension cachée, têtes d'attention, vocabulaire, context window
6. **Chargement modèle** : `AutoModelForCausalLM.from_pretrained(cache_dir)` avec thread de progression (log toutes les 15s)
7. **LoRA (si configuré)** :
   - Détection automatique des modules cibles via `_find_target_modules()` qui compare les modules demandés avec ceux du modèle
   - Fallback sur `KNOWN_LINEAR_NAMES` (q_proj, v_proj, k_proj, o_proj, gate_proj, up_proj, down_proj, c_attn, c_proj, c_fc, etc.)
   - Application via `get_peft_model(model, lora_config)`
8. **Tokenisation dataset** : format `"### Question: {question}\n### Answer: {answer}"`, padding max_length, labels = input_ids
9. **Entraînement** : `Trainer` de HuggingFace avec `TrainingArguments`, report_to="mlflow"
10. **Post-training** :
    - Log des métriques (loss, perplexity, runtime, samples/sec, steps/sec, FLOPs)
    - Fusion LoRA : `model.merge_and_unload()`
    - Sauvegarde modèle + tokenizer dans `OUTPUT_DIR/{model_name}`
    - Enregistrement artefacts MLflow + Model Registry
11. **Status → "evaluating"** (le worker d'évaluation prend le relais)

### MLScore training
Métriques remontées à l'API : `train_loss`, `perplexity`, `train_runtime`, `train_samples_per_second`

## Worker Evaluation (`workers/evaluation/worker.py`)

### Déclenchement
- Poll les runs avec `status=pending` ET `task_type=eval_only`
- Poll les runs avec `status=evaluating` (post-training)

### Étapes de `process_run(run)`

1. **Status → "evaluating"** + log de la config
2. **Chargement dataset évaluation** via `_resolve_eval_path()`
3. **Phase d'inférence (si finetune)** :
   - Charge le modèle entraîné depuis `OUTPUT_DIR/{model_name}`
   - Génère les réponses pour chaque sample avec prompt : `"Context: {ctx}\n\nQuestion: {question}\n\nAnswer:"`
   - Paramètres de génération : `temperature=0.7`, `top_p=0.9`, `do_sample=True`
   - Remplace les réponses du dataset par les réponses générées
   - Libère la mémoire du modèle (`del model` + `torch.cuda.empty_cache()`)
4. **Phase RAGAS** :
   - LLM juge : `ChatMistralAI(model=MISTRAL_MODEL, temperature=0)` via `LangchainLLMWrapper`
   - Embeddings : `MistralAIEmbeddings()` via `LangchainEmbeddingsWrapper`
   - Thread de progression (log toutes les 20s)
   - `evaluate(dataset=ds, metrics=selected_metrics, llm=evaluator_llm, embeddings=evaluator_embeddings)`
5. **Calcul MLScore** : moyenne pondérée des métriques RAGAS
   ```
   faithfulness: 0.30
   answer_relevancy: 0.20
   context_precision: 0.25
   context_recall: 0.25
   ```
6. **Logging** : scores par sample, scores moyens, MLflow run (params + métriques + artefact inference_results.json)
7. **Status → "completed"** + envoi des métriques à l'API

### Gestion NaN/Inf
Fonction `_safe_float(v)` : convertit toute valeur non-finie (NaN, Inf) en 0.0 avant envoi à l'API ou MLflow.

## Worker Security (`workers/security/worker.py`)

### Déclenchement
- Poll les runs avec `status=pending` ET `task_type=security_eval`

### Outils open source intégrés
- **garak** (NVIDIA, >=0.14) : scanner de vulnérabilités LLM (37+ probes)
- **modelscan** (ProtectAI, >=0.7) : analyse statique des fichiers modèle (pickle, safetensors)
- **DeepTeam** (Confident AI, >=1.0) : red teaming multi-tour (PII, biais, toxicité)
- **presidio-analyzer** (Microsoft, >=2.2) : détection PII dans les données d'entraînement
- **pip-audit** (PyPA, >=2.7) : audit CVE des dépendances Python

### Étapes de `process_run(run)`

1. **Status → "security_scanning"** + log de la config
2. **Phase 1 — Analyse statique** :
   - `modelscan` : scan des fichiers modèle dans `OUTPUT_DIR/{model_name}`
   - `pip-audit` : vérification des CVE des dépendances
   - Hash SHA-256 de tous les artefacts modèle
3. **Phase 2 — Audit des données d'entraînement** :
   - `presidio-analyzer` : détection PII dans le dataset d'entraînement
   - Vérification d'intégrité : JSON valide, champs requis, hash du fichier
4. **Phase 3 — Tests dynamiques** :
   - `garak` : probes promptinject, encoding, xss, leakreplay, snowball, donotanswer
   - `DeepTeam` : PII leakage, biais, toxicité (multi-tour)
5. **Calcul MLSecScore** : moyenne pondérée par catégorie OWASP
   ```
   sec_prompt_injection  : 0.20
   sec_output_handling   : 0.10
   sec_data_poisoning    : 0.15
   sec_supply_chain      : 0.15
   sec_info_disclosure   : 0.15
   sec_overreliance      : 0.10
   sec_model_dos         : 0.10
   sec_model_theft       : 0.05
   ```
6. **Logging** : scores OWASP, MLflow run (métriques + artefact security_report.json)
7. **Status → "completed"** + envoi des métriques à l'API

### Mapping OWASP Top 10

| Risque OWASP | Métrique | Outil |
|---|---|---|
| LLM01 — Injection d'invites | `sec_prompt_injection` | garak |
| LLM02 — Sorties non sécurisées | `sec_output_handling` | garak + DeepTeam |
| LLM03 — Empoisonnement des données | `sec_data_poisoning` | presidio + intégrité |
| LLM04 — Déni de service | `sec_model_dos` | garak |
| LLM05 — Chaîne logistique | `sec_supply_chain` | modelscan + pip-audit |
| LLM06 — Divulgation d'informations | `sec_info_disclosure` | garak + DeepTeam |
| LLM09 — Dépendance excessive | `sec_overreliance` | garak |
| LLM10 — Vol de modèle | `sec_model_theft` | Hash intégrité |

## Communication entre workers

Les workers ne communiquent **jamais directement** entre eux. La coordination se fait via l'API :
- Training finit → status passe à "evaluating"
- Evaluation poll → détecte les runs "evaluating" → traite
- Security poll → détecte les runs "pending" + "security_eval" → traite indépendamment
